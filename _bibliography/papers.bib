---
---
@inproceedings{si2024tabunite,
  title={TabGrad: Tabular Learning by Critiquing Automatic Text “Differentiation”},
  author={Si, Jacob and Qu, Mike and Ou, Zijing and Li, Yingzhen and Montjoye, Yves-Alexandre de},
  booktitle={Submission.},
  abstract={}
  year={2024},
  abbr={},
  pdf={},
  code={},
  selected={true}
}

@inproceedings{si2024tabunite,
  title={TabUnite: An Efficient Encoding Framework for Tabular Data Generation},
  author={Si, Jacob and Ou, Zijing and Qu, Mike and Li, Yingzhen},
  booktitle={Submission.},
  abstract={Generative models for tabular data face a long-standing challenge in the effective modelling of heterogeneous feature interrelationships, especially for generating tabular data with both continuous and categorical input features. Capturing these interrelationships is crucial as it allows models to understand complex patterns and dependencies that exist in the underlying data. A promising option to address the challenge is to devise suitable encoding/embedding schemes for the input features before the generative modelling process. However, prior methods often rely on either suboptimal heuristics such as one-hot encoding of discrete features and separated modelling of discrete/continuous features, or latent space generative models. Instead, our proposed solution leverages efficient continuous encodings to unify the data space and applies a single generative process across all the encodings jointly, thereby efficiently capturing heterogeneous feature interrelationships. Specifically, it employs encoding schemes such as Analog Bits or Dictionary Encoding that effectively convert discrete features into continuous ones. Extensive experiments on real-world and synthetic tabular datasets comprising of heterogeneous features demonstrate that our encoding schemes, combined with Flow Matching as the generative model, significantly enhances model capabilities. Our models, TabUnite-i2bFlow and TabUnite-dicFlow, are able to address data heterogeneity, achieving superior performances across a broad suite of datasets, baselines, and benchmarks while generating accurate, robust, and diverse tabular data.},
  year={2024},
  abbr={},
  pdf={tabunite.pdf},
  code={https://github.com/jacobyokehongsi/TabUnite},
  selected={true}
}

@inproceedings{si2024interpretabnet,
  title={InterpreTabNet: Distilling Predictive Signals from Tabular Data by Salient Feature Interpretation},
  author={Si, Jacob and Cheng, Wendy Yusi and Cooper, Michael and Krishnan, Rahul},
  booktitle={the 41st International Conference on Machine Learning, 2024.},
  abstract={Tabular data are omnipresent in various sectors of industries. Neural networks for tabular data such as TabNet have been proposed to make predictions while leveraging the attention mechanism for interpretability. However, the inferred attention masks are often dense, making it challenging to come up with rationales about the predictive signal. To remedy this, we propose InterpreTabNet, a variant of the TabNet model that models the attention mechanism as a latent variable sampled from a Gumbel-Softmax distribution. This enables us to regularize the model to learn distinct concepts in the attention masks via a KL Divergence regularizer. It prevents overlapping feature selection by promoting sparsity which maximizes the model's efficacy and improves interpretability to determine the important features when predicting the outcome. To assist in the interpretation of feature interdependencies from our model, we employ a large language model (GPT-4) and use prompt engineering to map from the learned feature mask onto natural language text describing the learned signal. Through comprehensive experiments on real-world datasets, we demonstrate that InterpreTabNet outperforms previous methods for interpreting tabular data while attaining competitive accuracy.},
  year={2024},
  abbr={ICML},
  honor={Spotlight Presentation [top 3.5%]},
  award={Spotlight},
  pdf={https://arxiv.org/abs/2406.00426},
  code={https://github.com/jacobyokehongsi/InterpreTabNet},
  selected={true}
}

@incollection{si2022assessing,
  title={Assessing Infant Mortality Rate: Problems stemming from Household Living Conditions, Women’s Education and Health},
  author={Si, Jacob and Alexander, Rohan},
  booktitle={"Telling Stories with Data: With Applications in R" by Rohan Alexander},
  abstract={What areas can be improved in order to promote the well-being of women in India and hence, reduce the infant mortality rate? Utilizing the data from the 1998-1999 India National Family Health Survey provided by the Demographic and Health Survey (DHS) program, we look to depict the demographics of Indian women and infants in different states of India. We have found that the root causes of poor infant mortality rates stem from having poor living conditions that affect the likelihood of women to attain education and understand the importance of antenatal care and birth delivery assistance. We also explore other factors such as potentially inheritable traits (unhealthy body weight and anaemia disease) as well as an infant’s diet. These factors are crucial in the development of an infant and the reduction of the infant mortality rate.},
  year={2022},
  abbr={Book Chapter},
  publisher={CRC Press},
  pdf={https://tellingstorieswithdata.com/inputs/pdfs/paper-4-2022-jacob_yoke_hong_si.pdf},
  selected={true}
}
